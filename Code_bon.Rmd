---
title: "Untitled"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
knitr::opts_chunk$set(echo = TRUE)
library(kableExtra)
library(ggplot2)
library(dplyr)
library(papeR)
library(mice)
library(visdat)
library(VIM)
library(epiDisplay)
library(lattice)
library(nlme)
library(splines)
library(survival)
library(JM)
set.seed(1)
```

```{r}
#######################################################
# Préparation de la table df (une ligne par individu) #
#######################################################
#Import de la table
df = read.delim("base_3C_CVideal.txt")
head(df)
#Mise en majuscule du nom des variables
names(df) = toupper(names(df))
#Vérification de l'absence de données manquantes
nrow(df[is.na.data.frame(df),])
#Exclusion des patients dont on ne dispose pas du premier CESD
df %>% filter (is.na(CESDT0) & is.na(CESDT1) & is.na(CESDT2) & is.na(CESDT4) & is.na(CESDT5) & is.na(CESDT6))
df <- df[-c(621,3874,5039,5432,5433),]
#Vérification du type de variables
sapply(df,class)
#Correction du type de variables
df$DC6 = as.factor(df$DC6)
df$SEXE = as.factor(df$SEXE)
df$DEM0_6 = as.factor(df$DEM0_6)
df$CENTRE = as.factor(df$CENTRE)
df$ETUDE_CLAS0 = as.factor(df$ETUDE_CLAS0)
df$ANTIDEP0 = as.factor(df$ANTIDEP0)
#Vérification de la correction des types de variables
sapply(df,class)
#Création des labels des variables
labels(df) = c("Indicateur de décès",
               "Âge au décès ou âge aux dernières nouvelles",
               "Sexe",
               "Score de CES-D à T0",
               "Âge à l'inclusion",
               "Indicateur de démence incidente",
               "Âge de démence incidente ou temps de censure",
               "Ville de la cohorte (1:Bordeaux, 2:Dijon, 3:Montpellier)",
               "Niveau d'études en classes (1: sans études ou primaire, 2: secondaire court, 3: secondaire long, 4: enseignement supérieur",
               "Traitement antidépresseur à l'inclusion (1: oui, 0: non",
               "Âge à la visite de suivi 1",
               "Âge à la visite de suivi 2",
               "Âge à la visite de suivi 4",
               "Âge à la visite de suivi 5",
               "Âge à la visite de suivi 6",
               "Score de santé cardiovasculaire total",
               "Score de santé cardiovasculaire optimale",
               "Score CES-D à la visite de suivi 1",
               "Score CES-D à la visite de suivi 2",
               "Score CES-D à la visite de suivi 4",
               "Score CES-D à la visite de suivi 5",
               "Score CES-D à la visite de suivi 6",
               "Identifiant du sujet")
#################################################################
# Mise en forme de la table shatter (une ligne par observation) #
#################################################################
shatter = read.csv("ShatteredDataFrame.csv")
head(shatter)
#Suppression de la première colonne "X"
shatter=shatter[,2:ncol(shatter)]
head(shatter)
#Suppression des individus dont on ne dispose pas du premier score CESD
supp <- (is.na(shatter$CESDT0) & is.na(shatter$CESDT1) & is.na(shatter$CESDT2) & is.na(shatter$CESDT4) & is.na(shatter$CESDT5) & is.na(shatter$CESDT6))
shatter <- shatter[!supp,]
shatter$AGECENTER = (shatter$AGE0 - 75)/5
#Vérification du type des variables
sapply(shatter,class)
#Correction du type des variables
shatter$DC6 = as.factor(shatter$DC6)
shatter$SEXE = as.factor(shatter$SEXE)
shatter$DEM0_6 = as.factor(shatter$DEM0_6)
shatter$CENTRE = as.factor(shatter$CENTRE)
shatter$ETUDE_CLAS0 = as.factor(shatter$ETUDE_CLAS0)
shatter$ANTIDEP0 = as.factor(shatter$ANTIDEP0)
#Vérification de la correction du type des variables
sapply(shatter,class)
```


### Analyse descriptive

##### Caractéristiques des sujets de l'étude

```{r}
sapply(c("factor","numeric"),
       papeR::summarise,
       data = df)
sumn = papeR::summarise(data = df,type="numeric",labels = T)[c(2,3,10,11),c(1,9,10,11)]
sumf = papeR::summarise(data = df,type="factor",labels = T)
kable(summ)
kable(sumf)
```

##### Nombre de mesures par sujet

```{r}
ndmes = table(shatter$ID[!is.na(shatter$CESDTVISITE)])
table(ndmes)
plot(table(ndmes))
```

##### Représentation graphique

###### **Spaghetti plots**

```{r}
# Pour améliorer la visibilité, on sélectionne un sous-échantillon des ID dont
# l'ID est multiple de 10.
# On retrouve le nombre de sujets par :
shatter[shatter$ID%%10==0,]$ID %>% unique %>% length
color <- shatter$ID
xyplot(CESDTVISITE ~ AGEVISITE-AGE0,
       group=ID,
       data=shatter[shatter$ID%%10==0,],
       col=color,
       lwd=1,
       type = 'l',bty="n",
       xlab = "Délai depuis l'entrée",
       ylab = "Score CESD",
       main = "Trajectoire du score CESDT par individu (sous-échantillon de 662 sujets")
```
```{r}
p <- (ggplot(shatter)
+ geom_line(aes(x = AGEVISITE-AGE0, y = CESDTVISITE, group = ID), color="grey30", alpha = 0.8)
+ stat_smooth(aes(x = AGEVISITE-AGE0, y = CESDTVISITE), method = "loess", size = 0.)
+ theme_bw()
+ xlab("Délai depuis l'entrée dans la cohorte (en années)")
+ ylab("Score CESDT")
)
p
```

### Vérification de la normalité de la distribution de la variable d'intérêt

```{r}
par(mfrow=c(2,3))
hist(df$CESDT0,na.rm=T)
hist(df$CESDT1,na.rm=T)
hist(df$CESDT2,na.rm=T)
hist(df$CESDT4,na.rm=T)
hist(df$CESDT5,na.rm=T)
hist(df$CESDT6,na.rm=T)
```

On constate que la distribution de la variable n'est pas normale. On propose deux transformations : logarithmique et quadratique

```{r}
#Transformation en log
par(mfrow=c(2,3))
hist(log(df$CESDT0+1),na.rm=T)
hist(log(df$CESDT1+1),na.rm=T)
hist(log(df$CESDT2+1),na.rm=T)
hist(log(df$CESDT4+1),na.rm=T)
hist(log(df$CESDT5+1),na.rm=T)
hist(log(df$CESDT6+1),na.rm=T)
#Transformation quadratique
hist(sqrt(df$CESDT0),na.rm=T)
hist(sqrt(df$CESDT1),na.rm=T)
hist(sqrt(df$CESDT2),na.rm=T)
hist(sqrt(df$CESDT4),na.rm=T)
hist(sqrt(df$CESDT5),na.rm=T)
hist(sqrt(df$CESDT6),na.rm=T)
```


```{r}
shatter$LOGCESDT = log(shatter$CESDTVISITE+1)
shatter$DELAI = shatter$AGEVISITE-shatter$AGE0
```

### Présentation du modèle de régression

On propose le modèle suivant :

$$
Y_{ij} = (\beta_{0}+\alpha_{0i}+\beta_{2}^{T}X_{ij})+(\beta_{1}+\alpha_{1i}+\beta_{3}^{T}X_{ij})t_{ij}+\epsilon_{ij}
$$

avec :
$$
\alpha = \begin{pmatrix}\alpha_{0i} \\ \alpha_{1i}\end{pmatrix} \sim\mathcal{N}\big( 0,\mathcal{B}\big)
$$
et

$$
\epsilon_{ij} \sim \mathcal{N}(0,\sigma_{e}^{2})
$$

### Modèle univarié

##### Pertinence des effets aléatoires

```{r}
#Modèle vide avec effet aléatoire uniquement sur l'intercept
model_interc = lme(fixed = LOGCESDT ~ DELAI,
            data = shatter,
            random = ~ 1 | ID,
            method="ML",
            na.action=na.omit)
model_int_pente = lme(fixed = LOGCESDT ~ DELAI,
            data = shatter,
            random = ~ DELAI | ID,
            method="ML",
            na.action=na.omit)
#Comparaison des deux modèles
devm1m2 = 2*logLik(model_int_pente) - 2*logLik(model_interc)
devm1m2
pm1m2 = 0.5*(1-pchisq(devm1m2,df=2)) + 0.5*(1-pchisq(devm1m2,df=1))
pm1m2
```

Le test est manifestement significatif. L'ajout d'un effet aléatoire sur la pente améliore significativement le modèle.


##### Pertinence de l'indépendance des effets aléatoires

***A vérifier***

$$
P(\alpha_{0i}|\alpha_{1i})=P(\alpha_{0i})
$$

```{r}
m1indep = lme(fixed = LOGCESDT ~ DELAI,
              data = shatter,
              random = list(~ 1 |ID, ~-1 + DELAI|ID),
              method="ML",
              na.action=na.omit)
devm1indep = 2*logLik(model_int_pente) - 2*logLik(m1indep)
p = 1-pchisq(devm1indep ,df=1)
p
```

#### Linéarité de la relation entre variable d'intérêt et variable explictive (SOM)

```{r}
#A faire sur l'intercept
#Estimation de l'effet du gain d'un point au score SOM sur l'évolution du score
#CESDT au cours du temps
model_univ = lme(fixed = LOGCESDT ~ factor(SOM)*DELAI,
                 data = shatter,
                 random = ~DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
model_univ$coefficients$fixed
ylinsom = c(0,model_univ$coefficients$fixed[2:8])
#Estimation de l'évolution du score CESDT au cours du temps pour les sujets avec
# un score SOM de 0 à 7 :
coefSom = function(som){
  model = lme(fixed = LOGCESDT ~ DELAI,
                 data = shatter[shatter$SOM==som,],
                 random = ~DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
  return(model$coefficients$fixed[2])
}
xlinsom = 0:7
#On présente l'estimation de l'effet du score SOM sur l'évolution au cours du temps
#du score CESDT
#Sous l'hypothèse linéaire, l'effet du score SOM sur l'évolution au cours du temps
# est linéaire.
# On peut donc présenter l'hypothèse de linéarité par une droite, dont l'ordonnée
# est l'estimation de l'évolution du CESDT au cours du temps pour les SOM=0,
# et dont la pente est l'effet du gain d'un point SOM sur l'évolution au cours du temps
# A vérifier ++++
model_univ_lin = lme(fixed = LOGCESDT ~ SOM*DELAI,
                 data = shatter,
                 random = ~DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
plot(xlinsom,ylinsom,
     main = "effet du score SOM sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score SOM",
     ylab = "Effet d'une unité de temps sur le score CESDT")
abline(a=model_univ_lin$coefficients$fixed[3],
       b=model_univ_lin$coefficients$fixed[4])

## Pour avoir IC : 
intervals(model_univ,level=0.95,which="all")
```


On observe que l'hypothèse linéaire n'est pas acceptable. Le profil de la courbe est estimé par un modèle polynomial de degré trois :

```{r}
model_p3 = lme(fixed = LOGCESDT ~ DELAI*(SOM + I(SOM^2) + I(SOM^3)),
                 data = shatter[shatter$SOM < 7,],
                 random = ~DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
xlinsom=0:6
ylinsom=ylinsom[1:7]
yfit=c()
for(x in 0:6){
  yfit = append(yfit,model_p3$coefficients$fixed[2] 
                + x*model_p3$coefficients$fixed[6]
                + x^2*model_p3$coefficients$fixed[7]
                + x^3*model_p3$coefficients$fixed[8])
}
c(AIC(model_univ),AIC(model_p3))
plot(xlinsom,ylinsom,
     main = "effet du score SOM sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score SOM",
     ylab = "Effet d'une unité de temps sur le score CESDT")
abline(a=model_univ_lin$coefficients$fixed[3],
       b=model_univ_lin$coefficients$fixed[4],
       col="darkblue")
lines(xlinsom,yfit,col="darkred")
```
***Changer l'analyse stratifiée en factor(), et exprimer les IC***

```{r}
# Comparaison entre le modèle linéaire et la modélisation d'interaction
model = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + SOM
                                          + I(SOM^2)
                                          + I(SOM^3)),
                  data = shatter,
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.exclude)
model_lin = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + SOM),
                  data = shatter,
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)
model_spline = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + bs(SOM)),
                  data = shatter,
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)
#Comparaison des modèles
c(AIC(model_lin),
  AIC(model),
  AIC(model_spline))
# A vérifier ++
dev = 2*logLik(model) - 2*logLik(model_lin)
p = 1-pchisq(dev ,df=3)
p
```

On privilégie donc une interaction polynomiale.

#### Sélection des variables

L'ensemble des variables est conservé car facteurs de confusions connus.
```{r}
#On retient le modèle cubique comme modèle final
summary(model)
## Pour avoir IC ?
intervals(model,level=0.95,which="all")
```


#### Adéquation du modèle
```{r}
# plot résidus standardiés 
plot(model)
 
par(mfrow=c(1,2))
plot(density(model$coefficients$random$ID[,1],xlab="intercept",main="predicted random intercept"))
plot(density(model$coefficients$random$ID[,2],xlab="pente",main="predicted random slope"))
```


## Modèle avec SCORE


```{r}
#Estimation de l'effet du gain d'un point au SCORE sur l'évolution de CESDT au cours du temps
# On réalise l'analyse en retirant 1 au score pour que la classe de référence vale 0
df$SCORE0 = df$SCORE -1
shatter$SCORE0 = shatter$SCORE - 1
model_univ = lme(fixed = LOGCESDT ~ factor(SCORE0)*DELAI,
                 data = shatter,
                 random = ~DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
model_univ$coefficients$fixed
summary(model_univ)
#Estimation de l'évolution du score CESDT au cours du temps pour les sujets avec
# un score de 0 à 14 :
# Nb : pas de convergence pour ML avec le score 2, donc on estime par REML :
xlinscore = 1:14
ylinscore = c(0,model_univ$coefficients$fixed[16:28])
#On présente l'estimation de l'effet du SCORE sur l'évolution au cours du temps
#du score CESDT
#Sous l'hypothèse linéaire, l'effet du score sur l'évolution au cours du temps
# est linéaire.
# On peut donc présenter l'hypothèse de linéarité par une droite, dont l'ordonnée
# est l'estimation de l'évolution du CESDT au cours du temps pour les SOM=0,
# et dont la pente est l'effet du gain d'un point SOM sur l'évolution au cours du temps
model_score_lin = lme(fixed = LOGCESDT ~ SCORE0*DELAI,
                       data = shatter,
                       random = ~DELAI|ID,
                       method = "ML",
                       na.action = na.omit)
plot(xlinscore,ylinscore,
     main = "effet du score sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score",
     ylab = "Effet d'une unité de temps sur le score CESDT")
abline(a=model_score_lin$coefficients$fixed[3],
       b=model_score_lin$coefficients$fixed[4])
```

On note que la valeur 14 semble être un outlier. Elle concerne `{r}nrow(df[df$SCORE ==14,])` sujet. On recommence les analyses en excluant cette valeur unique.

```{r}
model_score_factor = lme(fixed = LOGCESDT ~ factor(SCORE0)*DELAI,
                 data = shatter[shatter$SCORE0 !=13,],
                 random = ~1 + DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
xlinscore = 1:13
ylinscore = c(0,model_score_factor$coefficients$fixed[15:26])
model_score_lin= lme(fixed = LOGCESDT ~ SCORE0*DELAI,
                 data = shatter[shatter$SCORE0 !=13,],
                 random = ~1+DELAI|ID,
                 method = "ML",
                 na.action = na.omit)
plot(xlinscore,ylinscore,
     main = "effet du score sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score",
     ylab = "Effet d'une unité de temps sur le score CESDT")
abline(a=model_score_lin$coefficients$fixed[3],
       b=model_score_lin$coefficients$fixed[4])
```

L'hypothèse d'un effet linéaire du score cardiovasculaire sur l'évolution du score CESDT au cours du temps ne peut là encore pas être retenue.

Pour modéliser l'interaction entre le score cardiovasculaire et le temps, on propose un modèle polynomial :

$$
\mathbb{E}(Y_{ij}) = (\beta_{0}+\alpha_{0i}+\beta_{0SCORE}\times SCORE_{ij})+\\
(\beta_{1}+\alpha_{1i}+\beta_{1SCORE}\times SCORE_{ij}+\beta_{1SCORE^{2}}\times SCORE^{2}_{ij}+\beta_{1SCORE^{3}}\times SCORE^{3}_{ij})t_{ij}
$$

```{r}
model_score_pol = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + factor(ETUDE_CLAS0)
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + SCORE0
                                          + I(SCORE0^2)
                                          + I(SCORE0^3)),
                  data = shatter[shatter$SCORE0 !=13,],
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)
ypred_pol = model_score_pol$coefficients$fixed[2] +
  (xlinscore-1)*model_score_pol$coefficients$fixed[22] +
  ((xlinscore-1)^2)*model_score_pol$coefficients$fixed[23] +
  ((xlinscore-1)^3)*model_score_pol$coefficients$fixed[24]
plot(1:13,ylinscore,
     main = "effet du score sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score",
     ylab = "Effet d'une unité de temps sur le score CESDT",
     ylim=c(-0.12,0.12))
lines(1:13,ypred_pol, col="darkred")
legend("topright",
       legend=c("Régression polynomiale"),
       lty = 1,
       col = c("darkred"))
```

On veut représenter l'intervalle de confiance autour des paramètres $\beta_{SCORE}$ :

$$
IC_{95\%}(\beta_{SCORE}+\beta_{SCORE^{2}}+\beta_{SCORE^{3}})=\beta_{SCORE}+\beta_{SCORE^{2}}+\beta_{SCORE^{3}} \pm U_{1-\alpha}+\sqrt{\mathbb{V}(\beta_{SCORE}+\beta_{SCORE^{2}}+\beta_{SCORE^{3}})}
$$

avec

$$
\mathbb{V}(\beta_{SCORE}+\beta_{SCORE^{2}}+\beta_{SCORE^{3}}) = \mathbb{V}(\beta_{SCORE}) + \mathbb{V}(\beta_{SCORE^{2}}) + \mathbb{V}(\beta_{SCORE^{3}}) \\+ Cov(\beta_{SCORE},\beta_{SCORE^{2}})+ Cov(\beta_{SCORE},\beta_{SCORE^{3}})+ Cov(\beta_{SCORE^{2}},\beta_{SCORE^{3}})
$$

```{r}
ypred_pol_bi = ypred_pol-qnorm(0.975)*sqrt(model_score_pol$varFix[2,2]
                                           + model_score_pol$varFix[22,22]
                                           + model_score_pol$varFix[23,23]
                                           + model_score_pol$varFix[24,24]
                                           + 2*model_score_pol$varFix[2,22]
                                           + 2*model_score_pol$varFix[2,23]
                                           + 2*model_score_pol$varFix[2,24]
                                           + 2*model_score_pol$varFix[22,23]
                                           + 2*model_score_pol$varFix[22,24]
                                           + 2*model_score_pol$varFix[23,24])
ypred_pol_bs = ypred_pol+qnorm(0.975)*sqrt(model_score_pol$varFix[2,2]
                                           + model_score_pol$varFix[22,22]
                                           + model_score_pol$varFix[23,23]
                                           + model_score_pol$varFix[24,24]
                                           + 2*model_score_pol$varFix[2,22]
                                           + 2*model_score_pol$varFix[2,23]
                                           + 2*model_score_pol$varFix[2,24]
                                           + 2*model_score_pol$varFix[22,23]
                                           + 2*model_score_pol$varFix[22,24]
                                           + 2*model_score_pol$varFix[23,24])
plot(1:13,ylinscore,
     main = "effet du score sur l'évolution du score CESDT au cours du temps, observé vs. prédit",
     xlab = "Score",
     ylab = "Effet d'une unité de temps sur le score CESDT",
     ylim=c(-0.12,0.12))
lines(1:13,ypred_pol, col="darkred")
lines(1:13,ypred_pol_bs, col="darkred", lty=2)
lines(1:13,ypred_pol_bi, col="darkred", lty=2)
legend("topright",
       legend=c("Régression polynomiale"),
       lty = 1,
       col = c("darkred"))
```

Mais ces intervalles de confiance correspondent à une variance globale, et ne représentent pas la dispersion de l'estimateur pour chaque niveau de score.

+++ A REVOIR +++
 #Pour avoir les IC ?
```{r}
summary(model_score_pol)
#Avoir les IC à 95%: 
intervals(model_score_pol,level=0.95,which="all")
```



On compare le modèle polynomial avec une régression par b-splines et à un modèle linéaire

```{r}
quantile(df$SCORE0,c(0.25,0.5,0.75))
model_score_bs = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + bs(SCORE0,knots=c(6,7,8))),
                  data = shatter[shatter$SCORE0 !=13,],
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)
model_score_lin = lme(fixed = LOGCESDT ~ DELAI*(factor(CENTRE)
                                          + ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + SCORE0),
                  data = shatter[shatter$SCORE0 !=13,],
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)
test_AIC = c(AIC(model_score_bs),
             AIC(model_score_pol),
             AIC(model_score_lin))
names(test_AIC) = c("Modèle avec Splines B",
                    "Modèle polynomial",
                    "Modèle linéaire")
test_AIC
```

On constate que le modèle polynomial a le meilleur AIC. On le compare au modèle linéaire :

```{r}
dev = 2*logLik(model_score_pol) - 2*logLik(model_score_lin)
p = 1-pchisq(dev ,df=3)
p
```

On conserve donc le modèle polynomial.

#### Interprétation des coefficients du modèle

```{r}
summary(model_score_pol)
```

Pour avoir les p_value globale : à finir par clem
```{r}
modelcentre = lme(fixed = LOGCESDT ~ DELAI*(ETUDE_CLAS0
                                          + SEXE
                                          + ANTIDEP0
                                          + AGECENTER
                                          + SCORE0
                                          + I(SCORE0^2)
                                          + I(SCORE0^3)),
                  data = shatter[shatter$SCORE0 !=13,],
                  random = ~ 1 + DELAI | ID,
                  method="ML",
                  na.action=na.omit)



devm <- 2*logLik(modelcentre) - 2*logLik(model_score_pol)
p <- 1-pchisq(devm, df=3 )
p
```

#### Adéquation du modèle

```{r}
plot(model_score_pol)
par(mfrow=c(1,2))
plot(density(model_score_pol$coefficients$random$ID[,1],xlab="intercept",main="predicted random intercept"))
plot(density(model_score_pol$coefficients$random$ID[,2],xlab="pente",main="predicted random slope"))
```
